{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b588ab",
   "metadata": {},
   "source": [
    "# üöÄ Step-by-Step Guide to Train a Churn Prediction Model\n",
    "\n",
    "This notebook will guide you through training a churn prediction model using customer data. We will prepare the data, train a classification model, evaluate it, and save the model for later use.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Import Libraries\n",
    "\n",
    "Import necessary Python libraries such as pandas, numpy, scikit-learn, and joblib.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: Load and Explore Data\n",
    "\n",
    "Load your cleaned and encoded dataset, perform basic exploration to understand the data structure and target distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3: Prepare Features and Target Variable\n",
    "\n",
    "Separate the dataset into feature variables (`X`) and the target variable (`y`), which is the churn flag.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4: Split Data into Training and Testing Sets\n",
    "\n",
    "Use `train_test_split` to create training and testing datasets, typically 70-80% for training and 20-30% for testing.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 5: Choose and Train the Model\n",
    "\n",
    "Select a classification algorithm: Logistic Regression and train it on the training data.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 6: Evaluate Model Performance\n",
    "\n",
    "Evaluate the model on the test set using accuracy, precision, recall, F1-score, and ROC-AUC metrics.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 7: Save the Trained Model\n",
    "\n",
    "Save the trained model using `joblib` or `pickle` for deployment or integration in the Streamlit app.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 8: Conclusion and Next Steps\n",
    "\n",
    "Summarize findings and discuss how the model can be used for real-time churn prediction and customer retention strategies.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9c88e",
   "metadata": {},
   "source": [
    "# Churn Prediction Model Features\n",
    "\n",
    "## Target Variable\n",
    "- **Attrition_Flag**  \n",
    "  The target variable we want to predict.  \n",
    "  Typically:  \n",
    "  - `0` = Customer did **not** churn  \n",
    "  - `1` = Customer **churned**\n",
    "\n",
    "## Feature Variables (Inputs for the Model)\n",
    "The following columns are used as features to predict churn:\n",
    "\n",
    "| Feature Name             | Description                            |\n",
    "|-------------------------|------------------------------------|\n",
    "| `Customer_Age`           | Age of the customer                  |\n",
    "| `Income_Category`        | Income group category                |\n",
    "| `Card_Category`          | Credit card type/category            |\n",
    "| `Months_Inactive_12_mon` | Number of months inactive in last 12 months |\n",
    "| `Avg_Utilization_Ratio`  | Average credit utilization ratio    |\n",
    "| `Total_Trans_Amt`        | Total transaction amount             |\n",
    "| `Credit_Limit`           | Credit limit on the card             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f744c550",
   "metadata": {},
   "source": [
    "# üìä Data Cleaning & Preparation for Churn Prediction\n",
    "\n",
    "## üéØ Goal\n",
    "\n",
    "Prepare the dataset for machine learning by:\n",
    "\n",
    "- Removing unnecessary columns\n",
    "- Keeping only important features\n",
    "- Preparing target column for prediction\n",
    "- Ensuring correct data types for ML models\n",
    "\n",
    "---\n",
    "\n",
    "## üîé Understanding the Dataset\n",
    "\n",
    "The original dataset includes:\n",
    "\n",
    "- Customer demographic and account information\n",
    "- Behavior & transaction metrics\n",
    "- Some columns already encoded\n",
    "- Some unnecessary columns (IDs, model probabilities)\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Why Do We Have Extra Columns After Nominal Encoding?\n",
    "\n",
    "We applied **Nominal Encoding** (One-Hot Encoding) on some categorical columns.\n",
    "\n",
    "### üîç Example:\n",
    "\n",
    "Original column:Card_Category ‚Üí ['Blue', 'Gold', 'Platinum', 'Silver']\n",
    "\n",
    "\n",
    "After one-hot encoding, we get 4 new columns:\n",
    "\n",
    "- `Card_Blue`\n",
    "- `Card_Gold`\n",
    "- `Card_Platinum`\n",
    "- `Card_Silver`\n",
    "\n",
    "‚úÖ This allows ML models to work with categorical variables as numerical binary columns.\n",
    "\n",
    "---\n",
    "\n",
    "## üö´ Columns to Remove\n",
    "\n",
    "| Column               | Reason                               |\n",
    "|----------------------|------------------------------------|\n",
    "| `Customer_ID`        | Unique ID ‚Äî no predictive power    |\n",
    "| `NB_Stay_Probability`| Model output ‚Äî causes data leakage |\n",
    "| `NB_Churn_Probability`| Model output ‚Äî causes data leakage |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Columns to Keep\n",
    "\n",
    "| Column Group          | Columns                                                                                  |\n",
    "|-----------------------|------------------------------------------------------------------------------------------|\n",
    "| **Demographics**      | `Customer_Age`, `Gender`, `Dependent_count`, `Education_Level`, `Income_Category`         |\n",
    "| **Account Info**      | `Tenure_Months`, `Products_Count`, `Months_Inactive_12_mon`, `Contacts_Count_12_mon`      |\n",
    "| **Credit Info**       | `Credit_Limit`, `Total_Revolving_Bal`, `Available_Credit`                                |\n",
    "| **Behavior**          | `Total_Amt_Chng_Q4_Q1`, `Total_Trans_Amt`, `Total_Trans_Ct`, `Total_Ct_Chng_Q4_Q1`, `Avg_Utilization_Ratio` |\n",
    "| **One-Hot Encoded**   | `Marital_Divorced`, `Marital_Married`, `Marital_Single`, `Marital_Unknown`, `Card_Blue`, `Card_Gold`, `Card_Platinum`, `Card_Silver` |\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Target Column\n",
    "\n",
    "| Column          | Description                    |\n",
    "|-----------------|-------------------------------|\n",
    "| `Attrition_Flag`| Churn label (0 = Stay, 1 = Churn) |\n",
    "\n",
    "---\n",
    "\n",
    "## üî¢ Data Type Adjustment\n",
    "\n",
    "The one-hot encoded columns are currently stored as `True` / `False`.  \n",
    "‚úÖ We will convert them into numerical `0` / `1` for machine learning.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c611a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Import Libraries\n",
    "\n",
    "# 1Ô∏è‚É£ Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f67fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
